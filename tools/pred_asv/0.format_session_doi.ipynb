{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "913ec4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from pyproj import Transformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.shutil import copy\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "RAW_PRED_FOLDER = Path(\"./data/PREDICTIONS_RASTER\")\n",
    "MERGED_RASTERS = Path(\"./data/merged_rasters\")\n",
    "COLORED_RASTERS = Path(\"./data/colored_rasters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The get_path function try to match the session_name with a session on your computer.\n",
    "# Please, change the path to your local folder.\n",
    "\n",
    "\n",
    "def get_path(row):\n",
    "    name = row[\"session_name\"]\n",
    "\n",
    "    date = name.split(\"_\")[0][0:6]\n",
    "\n",
    "\n",
    "    letter_disk = \"\"\n",
    "    if date in [\"202312\", \"202311\"]:\n",
    "        letter_disk = \"D\"\n",
    "    elif date in [\"202211\", \"202309\", \"202310\"]:\n",
    "        letter_disk = \"E\"\n",
    "    else:\n",
    "        letter_disk = \"F\"\n",
    "\n",
    "    if 1 <= int(date[5]) <= 7 and int(date[3]) == 3 and int(date[4]) == 0 and \"MDG\" not in name:\n",
    "        date = \"202301-07\"\n",
    "\n",
    "    return f\"/media/bioeos/{letter_disk}/{date}_plancha_session\"\n",
    "\n",
    "\n",
    "# Working from file : https://zenodo.org/records/16924962/files/session_doi.csv?download=1\n",
    "df = pd.read_csv(\"session_doi.csv\")\n",
    "df = df[df['session_name'].str.contains('ASV', na=False)].reset_index()\n",
    "df[\"root_folder\"] = df.apply(lambda row: get_path(row), axis=1)\n",
    "df = df[[\"root_folder\", \"session_name\"]]\n",
    "\n",
    "# Verify if all \n",
    "for i, row in df.iterrows():\n",
    "    session_path = Path(row[\"root_folder\"], row[\"session_name\"])\n",
    "    if not session_path.exists():\n",
    "        print(session_path)\n",
    "\n",
    "df.to_csv(\"session_asv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679f914d",
   "metadata": {},
   "source": [
    "Use this script to scrap all IA files : https://github.com/SeatizenDOI/plancha-workflow/blob/master/utils/master_grab.py\n",
    "\n",
    "with this command : python master_grab.py -ecsv -pcsv /home/bioeos/Documents/project_hub/cog-server/tools/pred_asv/session_asv.csv -po /home/bioeos/Documents/project_hub/cog-server/tools/pred_asv/data -pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13ac798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we remove the useless class\n",
    "\n",
    "USEFUL_CLASS = [\"ACROPORE_BRANCHED\", \"ACROPORE_DIGITISED\", \"ACROPORE_SUB_MASSIVE\", \"ACROPORE_TABULAR\", \"ALGAE_ASSEMBLY\", \"ALGAE_DRAWN_UP\", \"ALGAE_LIMESTONE\", \"ALGAE_SODDING\", \"BLEACHED_CORAL\", \"DEAD_CORAL\", \"MILLEPORE\", \"NO_ACROPORE_ENCRUSTING\", \"NO_ACROPORE_FOLIACEOUS\", \"NO_ACROPORE_MASSIVE\", \"NO_ACROPORE_SOLITARY\", \"NO_ACROPORE_SUB_MASSIVE\", \"ROCK\", \"RUBBLE\", \"SAND\", \"SYRINGODIUM_ISOETIFOLIUM\", \"THALASSODENDRON_CILIATUM\"]\n",
    "\n",
    "for folder in sorted(list(Path(RAW_PRED_FOLDER).iterdir())):\n",
    "    if folder.name in USEFUL_CLASS: continue\n",
    "\n",
    "    print(f\"Removing {folder.name}\")\n",
    "    shutil.rmtree(folder)\n",
    "    # print(f'\"{folder.name}\"', end=\", \") # Use this line to show in list format all tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec2ad1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell gather all functions necessary to produce the merged raster.\n",
    "\n",
    "def get_raster_bbox(raster_path):\n",
    "    \"\"\"Extract the bounding box of a raster file in EPSG:3857 (meters).\"\"\"\n",
    "    with rasterio.open(raster_path) as dataset:\n",
    "        bounds = dataset.bounds  # (left, bottom, right, top)\n",
    "\n",
    "        # Convert coordinates to meters (EPSG:4326 to EPSG:3857)\n",
    "        transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3857\", always_xy=True)\n",
    "        min_x, min_y = transformer.transform(bounds.left, bounds.bottom)\n",
    "        max_x, max_y = transformer.transform(bounds.right, bounds.top)\n",
    "\n",
    "        return min_x, min_y, max_x, max_y, raster_path\n",
    "\n",
    "def bbox_distance(bbox1, bbox2):\n",
    "    \"\"\"Compute the minimum distance between two bounding boxes.\"\"\"\n",
    "    min_x1, min_y1, max_x1, max_y1, _ = bbox1\n",
    "    min_x2, min_y2, max_x2, max_y2, _ = bbox2\n",
    "\n",
    "    # Compute horizontal and vertical distances\n",
    "    dx = max(min_x2 - max_x1, min_x1 - max_x2, 0)  # Distance along x-axis\n",
    "    dy = max(min_y2 - max_y1, min_y1 - max_y2, 0)  # Distance along y-axis\n",
    "\n",
    "    return np.hypot(dx, dy)  # Euclidean distance\n",
    "\n",
    "def group_rasters_by_bbox(raster_paths, distance_threshold=10):\n",
    "    \"\"\"Groups raster files based on bounding box proximity.\"\"\"\n",
    "    bboxes = [get_raster_bbox(path) for path in raster_paths]\n",
    "\n",
    "    # Compute pairwise distance matrix\n",
    "    distance_matrix = np.zeros((len(bboxes), len(bboxes)))\n",
    "    for i in range(len(bboxes)):\n",
    "        for j in range(len(bboxes)):\n",
    "            if i != j:\n",
    "                distance_matrix[i, j] = bbox_distance(bboxes[i], bboxes[j])\n",
    "\n",
    "    # Use DBSCAN clustering\n",
    "    clustering = DBSCAN(eps=distance_threshold, min_samples=1, metric=\"precomputed\").fit(distance_matrix)\n",
    "\n",
    "    # Organize rasters by cluster labels\n",
    "    grouped_rasters = {}\n",
    "    for bbox, label in zip(bboxes, clustering.labels_):\n",
    "        if label not in grouped_rasters:\n",
    "            grouped_rasters[label] = []\n",
    "        grouped_rasters[label].append(bbox)\n",
    "\n",
    "    return list(grouped_rasters.values())\n",
    "\n",
    "def merge_rasters_to_cog(groups, year, species, output_folder):\n",
    "    \"\"\"Merge each group into a single COG file.\"\"\"\n",
    "    output_folder = Path(output_folder)\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    for i, group in enumerate(groups):\n",
    "        raster_paths = [bbox[4] for bbox in group]  # Extract file paths\n",
    "        # print(f\"Generate {i}\")\n",
    "\n",
    "        # Open all rasters\n",
    "        datasets = [rasterio.open(path) for path in raster_paths]\n",
    "\n",
    "\n",
    "        # Merge the rasters\n",
    "        mosaic, out_transform = merge(datasets, resampling=Resampling.bilinear)\n",
    "\n",
    "        # Use metadata from first raster\n",
    "        out_meta = datasets[0].meta.copy()\n",
    "        out_meta.update({\n",
    "            \"driver\": \"COG\",\n",
    "            \"height\": mosaic.shape[1],\n",
    "            \"width\": mosaic.shape[2],\n",
    "            \"transform\": out_transform,\n",
    "            \"compress\": \"LZW\",\n",
    "            \"BIGTIFF\": \"IF_SAFER\"\n",
    "        })\n",
    "\n",
    "        merged_path = Path(output_folder, f\"tmp_{i}.tif\")\n",
    "\n",
    "        # Save the merged raster\n",
    "        with rasterio.open(merged_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(mosaic)\n",
    "\n",
    "        # Convert to COG\n",
    "        cog_path = Path(output_folder, f\"group_{year}_{species}_{i}.tif\")\n",
    "        copy(merged_path, cog_path, driver=\"COG\", compress=\"LZW\")\n",
    "\n",
    "        merged_path.unlink()\n",
    "\n",
    "        # Close datasets\n",
    "        for dataset in datasets:\n",
    "            dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4859f4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years found ['2022', '2023', '2024', '2025']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1/22 [00:04<01:35,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2/22 [00:09<01:30,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 3/22 [00:13<01:26,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 4/22 [00:18<01:22,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 5/22 [00:22<01:16,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 6/22 [00:27<01:12,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 7/22 [00:31<01:08,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 8/22 [00:36<01:03,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 9/22 [00:40<00:57,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 10/22 [00:45<00:53,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 11/22 [00:49<00:47,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 12/22 [00:53<00:43,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 13/22 [00:57<00:39,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 14/22 [01:02<00:35,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 15/22 [01:06<00:31,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 16/22 [01:11<00:26,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 17/22 [01:16<00:22,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 18/22 [01:19<00:17,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 19/22 [01:24<00:12,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 20/22 [01:28<00:08,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 21/22 [01:32<00:04,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year 2024\n",
      "Working with year 2025\n",
      "Working with year 2022\n",
      "Working with year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:37<00:00,  4.43s/it]\n"
     ]
    }
   ],
   "source": [
    "years = list(set([a.name[0:4] for a in Path(RAW_PRED_FOLDER, \"SAND\").iterdir()]))\n",
    "\n",
    "print(f\"Years found {sorted(years)}\")\n",
    "\n",
    "# Clean output folder.\n",
    "if MERGED_RASTERS.exists():\n",
    "    shutil.rmtree(MERGED_RASTERS)\n",
    "\n",
    "\n",
    "for species_folder in tqdm(sorted(list(RAW_PRED_FOLDER.iterdir()))):\n",
    "    for year in years:\n",
    "        print(f\"Working with year {year}\")\n",
    "        raster_files = sorted([a for a in Path(species_folder).iterdir() if year in a.name])\n",
    "\n",
    "        groups = group_rasters_by_bbox(raster_files, distance_threshold=10)\n",
    "\n",
    "        output_folder = Path(MERGED_RASTERS, year)\n",
    "        output_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        cog_files = merge_rasters_to_cog(groups, year, species_folder.name, output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "756561e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\"Acropore_branched\": 0.351, \"Acropore_digitised\": 0.349, \"Acropore_sub_massive\": 0.123, \"Acropore_tabular\": 0.415, \"Algae_assembly\": 0.434, \"Algae_drawn_up\": 0.193, \"Algae_limestone\": 0.346, \"Algae_sodding\": 0.41, \"Atra/Leucospilota\": 0.586, \"Bleached_coral\": 0.408, \"Blurred\": 0.3, \"Dead_coral\": 0.407, \"Fish\": 0.466, \"Homo_sapiens\": 0.402, \"Human_object\": 0.343, \"Living_coral\": 0.208, \"Millepore\": 0.292, \"No_acropore_encrusting\": 0.227, \"No_acropore_foliaceous\": 0.462, \"No_acropore_massive\": 0.333, \"No_acropore_solitary\": 0.415, \"No_acropore_sub_massive\": 0.377, \"Rock\": 0.476, \"Sand\": 0.548, \"Rubble\": 0.417, \"Sea_cucumber\": 0.357, \"Sea_urchins\": 0.335, \"Sponge\": 0.152, \"Syringodium_isoetifolium\": 0.476, \"Thalassodendron_ciliatum\": 0.209, \"Useless\": 0.315}\n",
    "thresholds = {k.upper():v for k, v in thresholds.items()}\n",
    "\n",
    "\n",
    "color_map = {k.upper(): np.array([random.randint(100, 255),  # R\n",
    "                        random.randint(100, 255),  # G\n",
    "                        random.randint(100, 255)]) for k in thresholds}\n",
    "color_map_to_save = {k: v.tolist() for k,v in color_map.items()}\n",
    "\n",
    "with open('color_asv_pred_by_specie.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(color_map_to_save, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4c6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_raster_color(raster_path, output_tif, threshold, base_color):\n",
    "\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        band = src.read(1)\n",
    "        profile = src.profile\n",
    "\n",
    "        # Replace NaN with 0 for safe math\n",
    "        band_clean = np.where(np.isnan(band), 0, band)\n",
    "\n",
    "        # Keep values in [0,1] range\n",
    "        band_norm = np.clip(band_clean, 0, 1)\n",
    "\n",
    "        # Mask: true if pixel should be transparent (below threshold OR NaN)\n",
    "        mask = (band_norm < threshold) | np.isnan(band)\n",
    "\n",
    "        # Build RGBA\n",
    "        rgba = np.zeros((4, band.shape[0], band.shape[1]), dtype=np.uint8)\n",
    "\n",
    "        # Blend from white → base_color\n",
    "        for c in range(3):  # R,G,B\n",
    "            rgba[c] = (255 * (1 - band_norm) + base_color[c] * band_norm).astype(np.uint8)\n",
    "        rgba[3] = 255  # default opaque\n",
    "        rgba[:, mask] = 0  # all channels 0 if transparent\n",
    "\n",
    "        # Update profile for RGBA with explicit alpha\n",
    "        profile.update(\n",
    "            count=4,\n",
    "            dtype=\"uint8\",\n",
    "            photometric=\"RGBA\",\n",
    "            compress=\"LZW\",\n",
    "            nodata=None\n",
    "        )\n",
    "        profile.pop(\"nodata\", None)\n",
    "\n",
    "        with rasterio.open(output_tif, \"w\", **profile) as dst:\n",
    "            dst.write(rgba)\n",
    "            dst.set_band_description(1, \"Red\")\n",
    "            dst.set_band_description(2, \"Green\")\n",
    "            dst.set_band_description(3, \"Blue\")\n",
    "            dst.set_band_description(4, \"Alpha\")  # mark alpha band\n",
    "            dst.colorinterp = (\n",
    "                rasterio.enums.ColorInterp.red,\n",
    "                rasterio.enums.ColorInterp.green,\n",
    "                rasterio.enums.ColorInterp.blue,\n",
    "                rasterio.enums.ColorInterp.alpha\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e41c82d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/merged_rasters/2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [00:05<00:00, 46.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/merged_rasters/2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 528/528 [00:10<00:00, 51.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/merged_rasters/2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [00:03<00:00, 48.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/merged_rasters/2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:02<00:00, 56.07it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Clean output folder.\n",
    "if COLORED_RASTERS.exists():\n",
    "    shutil.rmtree(COLORED_RASTERS)\n",
    "\n",
    "\n",
    "for year in sorted(list(MERGED_RASTERS.iterdir())):\n",
    "    print(year)\n",
    "    for raster in tqdm(sorted(list(year.iterdir()))):\n",
    "\n",
    "        year_output = Path(COLORED_RASTERS, year.name)\n",
    "        year_output.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        output_file = Path(year_output, f\"{raster.stem}_colored.tif\")\n",
    "\n",
    "        name_split = raster.name.split(\"_\")\n",
    "        species = \"_\".join(name_split[2:len(name_split)-1])\n",
    "        threshold = thresholds.get(species, 0.5)\n",
    "        color = color_map.get(species, (255, 100, 100))\n",
    "        \n",
    "        create_raster_color(raster, output_file, threshold, color)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cog_server_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
